(08-11) 22:35:09 INFO     [aggregator.py:10] Job args Namespace(adam_epsilon=1e-08, adaptation_mode=0, aggregator_device=0, backbone='./resnet50.pth', backend='gloo', batch_size=20, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cfg_file='./utils/rcnn/cfgs/res101.yml', clip_bound=0.9, clock_factor=6.046931407942239, conf_path='~/dataset/', cuda_device=None, cut_off_util=0.05, data_cache='', data_dir='/homes/zjiangaj/FedScale/dataset/data/reddit', data_map_file='/homes/zjiangaj/FedScale/dataset/data/reddit/client_data_mapping/train.csv', data_set='blog', decay_epoch=10, decay_factor=0.98, device_avail_file='/homes/zjiangaj/FedScale/dataset/data/device_info/client_behave_trace', device_conf_file='/homes/zjiangaj/FedScale/dataset/data/device_info/client_device_capacity', dump_epoch=10000000000.0, epochs=7, eval_interval=2, exploration_alpha=0.3, exploration_decay=0.98, exploration_factor=0.9, exploration_min=0.3, filter_less=21, filter_more=1000000000000000.0, finetune=False, gradient_policy=None, hidden_layers=7, hidden_size=256, input_dim=0, job_name='reddit_random_none', labels_path='labels.json', learners='1-2-3-4', learning_rate=4e-05, line_by_line=False, local_steps=4, log_path='/homes/zjiangaj/FedScale/core/evals', loss_decay=0.2, malicious_factor=1000000000000000.0, manager_port=16258, min_learning_rate=1e-05, mlm=False, mlm_probability=0.15, model='albert-base-v2', model_size=65536, noise_dir=None, noise_factor=0.1, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=10, num_classes=35, num_loaders=4, output_dim=0, overcommitment=1.3, overwrite_cache=False, pacer_delta=5, pacer_step=20, personalized='none', proxy_mu=0.1, ps_ip='127.0.0.1', ps_port='56434', rnn_type='lstm', round_penalty=2.0, round_threshold=30, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, spec_augment=False, speed_volume_perturb=False, task='nlp', test_bsz=20, test_interval=20, test_manifest='data/test_manifest.csv', test_mode='default', test_output_dir='./logs/server', test_ratio=1.0, test_size_file='', this_rank=0, time_stamp='0811_223337', total_worker=5, train_manifest='data/train_manifest.csv', train_size_file='', train_uniform=False, upload_epoch=20, use_cuda=True, vocab_tag_size=500, vocab_token_size=10000, weight_decay=0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.9, yogi_beta2=0.99, yogi_eta=0.003, yogi_tau=1e-08)
(08-11) 22:35:09 INFO     [executor.py:44] (EXECUTOR:2) is setting up environ ...
(08-11) 22:35:09 INFO     [executor.py:44] (EXECUTOR:1) is setting up environ ...
(08-11) 22:35:09 INFO     [executor.py:44] (EXECUTOR:4) is setting up environ ...
(08-11) 22:35:09 INFO     [executor.py:44] (EXECUTOR:3) is setting up environ ...
(08-11) 22:35:11 INFO     [executor.py:81] Start to connect to 127.0.0.1:16258 for control plane communication ...
(08-11) 22:35:11 INFO     [executor.py:81] Start to connect to 127.0.0.1:16258 for control plane communication ...
(08-11) 22:35:11 INFO     [executor.py:81] Start to connect to 127.0.0.1:16258 for control plane communication ...
(08-11) 22:35:11 INFO     [executor.py:81] Start to connect to 127.0.0.1:16258 for control plane communication ...
(08-11) 22:35:17 INFO     [aggregator.py:86] End up with cuda device (cuda:0)
(08-11) 22:35:17 INFO     [aggregator.py:106] Start to initiate 127.0.0.1:16258 for control plane communication ...
(08-11) 22:35:19 INFO     [distributed_c10d.py:194] Added key: store_based_barrier_key:1 to store for rank: 0
(08-11) 22:35:19 INFO     [distributed_c10d.py:194] Added key: store_based_barrier_key:1 to store for rank: 1
(08-11) 22:35:19 INFO     [distributed_c10d.py:194] Added key: store_based_barrier_key:1 to store for rank: 2
(08-11) 22:35:19 INFO     [distributed_c10d.py:194] Added key: store_based_barrier_key:1 to store for rank: 4
(08-11) 22:35:19 INFO     [distributed_c10d.py:194] Added key: store_based_barrier_key:1 to store for rank: 3
(08-11) 22:35:19 INFO     [distributed_c10d.py:225] Rank 2: Completed store-based barrier for 5 nodes.
(08-11) 22:35:19 INFO     [distributed_c10d.py:225] Rank 4: Completed store-based barrier for 5 nodes.
(08-11) 22:35:19 INFO     [distributed_c10d.py:225] Rank 3: Completed store-based barrier for 5 nodes.
(08-11) 22:35:19 INFO     [distributed_c10d.py:225] Rank 1: Completed store-based barrier for 5 nodes.
(08-11) 22:35:19 INFO     [distributed_c10d.py:225] Rank 0: Completed store-based barrier for 5 nodes.
(08-11) 22:35:19 INFO     [fllibs.py:78] Initializing the model ...
(08-11) 22:35:19 INFO     [fllibs.py:78] Initializing the model ...
(08-11) 22:35:19 INFO     [fllibs.py:78] Initializing the model ...
(08-11) 22:35:19 INFO     [fllibs.py:78] Initializing the model ...
(08-11) 22:35:19 INFO     [fllibs.py:78] Initializing the model ...
/data/samuel/anaconda3/envs/fedscale/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
  FutureWarning,
(08-11) 22:35:32 INFO     [aggregator.py:482] Start monitoring events ...
/data/samuel/anaconda3/envs/fedscale/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
  FutureWarning,
(08-11) 22:35:39 INFO     [nlp.py:91] Loading features from cached file /homes/zjiangaj/FedScale/dataset/data/reddit/train/albert-base-v2_cached_lm_62
/data/samuel/anaconda3/envs/fedscale/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
  FutureWarning,
(08-11) 22:35:39 INFO     [nlp.py:91] Loading features from cached file /homes/zjiangaj/FedScale/dataset/data/reddit/train/albert-base-v2_cached_lm_62
/data/samuel/anaconda3/envs/fedscale/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
  FutureWarning,
(08-11) 22:35:39 INFO     [nlp.py:91] Loading features from cached file /homes/zjiangaj/FedScale/dataset/data/reddit/train/albert-base-v2_cached_lm_62
/data/samuel/anaconda3/envs/fedscale/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
  FutureWarning,
(08-11) 22:35:39 INFO     [nlp.py:91] Loading features from cached file /homes/zjiangaj/FedScale/dataset/data/reddit/train/albert-base-v2_cached_lm_62
